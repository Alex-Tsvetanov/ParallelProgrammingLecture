\documentclass[aspectratio=169]{beamer}
\usepackage[utf8]{inputenc}
\usepackage[T2A]{fontenc}
\usepackage[bulgarian]{babel}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{tikz}
\usepackage{pgfplots}
\pgfplotsset{compat=1.18}
\usetikzlibrary{arrows.meta, positioning, shapes}

\usetheme{Berlin}
\usecolortheme{beaver}
\setbeamertemplate{headline}{}
%gets rid of bottom navigation bars
\setbeamertemplate{footline}[frame number]{}

%gets rid of bottom navigation symbols
%\setbeamertemplate{navigation symbols}{}

\setbeamercolor{item}{fg=alerted text.fg}
%\setbeamercolor{navigation symbols}{fg=alerted text.fg}
\setbeamercolor{structure}{fg=alerted text.fg}


%gets rid of footer
%will override 'frame number' instruction above
%comment out to revert to previous/default definitions
%\setbeamertemplate{footline}{}

% Настройки за код
\lstset{
    language=C++,
    basicstyle=\ttfamily\footnotesize,
    keywordstyle=\color{blue}\bfseries,
    commentstyle=\color{green!60!black},
    stringstyle=\color{red},
    numbers=left,
    numberstyle=\tiny\color{gray},
    stepnumber=1,
    numbersep=5pt,
    backgroundcolor=\color{gray!10},
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    frame=single,
    tabsize=2,
    captionpos=b,
    breaklines=true,
    breakatwhitespace=false,
    escapeinside={(*@}{@*)},
    morekeywords={thread, mutex, condition_variable, unique_lock, shared_ptr},
    literate=%
        {а}{{\selectfont\char224}}1 {б}{{\selectfont\char225}}1
        {в}{{\selectfont\char226}}1 {г}{{\selectfont\char227}}1
        {д}{{\selectfont\char228}}1 {е}{{\selectfont\char229}}1
        {ж}{{\selectfont\char230}}1 {з}{{\selectfont\char231}}1
        {и}{{\selectfont\char232}}1 {й}{{\selectfont\char233}}1
        {к}{{\selectfont\char234}}1 {л}{{\selectfont\char235}}1
        {м}{{\selectfont\char236}}1 {н}{{\selectfont\char237}}1
        {о}{{\selectfont\char238}}1 {п}{{\selectfont\char239}}1
        {р}{{\selectfont\char240}}1 {с}{{\selectfont\char241}}1
        {т}{{\selectfont\char242}}1 {у}{{\selectfont\char243}}1
        {ф}{{\selectfont\char244}}1 {х}{{\selectfont\char245}}1
        {ц}{{\selectfont\char246}}1 {ч}{{\selectfont\char247}}1
        {ш}{{\selectfont\char248}}1 {щ}{{\selectfont\char249}}1
        {ъ}{{\selectfont\char250}}1 {ь}{{\selectfont\char252}}1
        {ю}{{\selectfont\char254}}1 {я}{{\selectfont\char255}}1
        {А}{{\selectfont\char192}}1 {Б}{{\selectfont\char193}}1
        {В}{{\selectfont\char194}}1 {Г}{{\selectfont\char195}}1
        {Д}{{\selectfont\char196}}1 {Е}{{\selectfont\char197}}1
        {Ж}{{\selectfont\char198}}1 {З}{{\selectfont\char199}}1
        {И}{{\selectfont\char200}}1 {Й}{{\selectfont\char201}}1
        {К}{{\selectfont\char202}}1 {Л}{{\selectfont\char203}}1
        {М}{{\selectfont\char204}}1 {Н}{{\selectfont\char205}}1
        {О}{{\selectfont\char206}}1 {П}{{\selectfont\char207}}1
        {Р}{{\selectfont\char208}}1 {С}{{\selectfont\char209}}1
        {Т}{{\selectfont\char210}}1 {У}{{\selectfont\char211}}1
        {Ф}{{\selectfont\char212}}1 {Х}{{\selectfont\char213}}1
        {Ц}{{\selectfont\char214}}1 {Ч}{{\selectfont\char215}}1
        {Ш}{{\selectfont\char216}}1 {Щ}{{\selectfont\char217}}1
        {Ъ}{{\selectfont\char218}}1 {Ь}{{\selectfont\char220}}1
        {Ю}{{\selectfont\char222}}1 {Я}{{\selectfont\char223}}1
}

\title{Модерни техники за паралелизъм и асинхронност в C++}
\subtitle{Thread Pools, Coroutines и Publisher/Subscriber Pattern}
\author{Алекс Цветанов, КСИ, ФКСТ, 121222225}
\institute{Паралелно програмиране}
\date{\today}

\begin{document}

\begin{frame}
\titlepage
\end{frame}

\begin{frame}{План на лекцията}
\begin{columns}[t]
\column{0.5\textwidth}
\tableofcontents[sections={1-3}]

\column{0.5\textwidth}
\tableofcontents[sections={4-6}]
\end{columns}
\end{frame}

\section{Увод: Паралелизъм vs Асинхронност}

\begin{frame}{Мотивация}
\begin{columns}
\column{0.5\textwidth}
\textbf{Защо е важно?}
\begin{itemize}
    \item Съвременните CPU имат множество ядра
    \item I/O операциите блокират нишки
    \item Нуждата от high-throughput системи
    \item Скалируемост и ефективност
\end{itemize}

\column{0.5\textwidth}
\textbf{Нашият фокус днес:}
\begin{enumerate}
    \item Thread Pools (паралелизъм)
    \item Coroutines (асинхронност)
    \item Publisher/Subscriber (комуникация)
    \item Lock-free структури
    \item Практически имплементации
\end{enumerate}
\end{columns}

\vspace{0.5cm}
\centering
\textit{Как да използваме ресурсите оптимално?}
\end{frame}

\begin{frame}{Паралелизъм vs Асинхронност}
\begin{center}
\begin{tikzpicture}[scale=0.7]
    % Parallelism - LEFT SIDE
    \node[font=\bfseries] at (0,2.8) {Паралелизъм};
    \draw[fill=green!20, thick] (0,1.8) rectangle (1.5,2.3) node[pos=.5] {\tiny Task 1};
    \draw[fill=green!20, thick] (0,1.2) rectangle (1.5,1.7) node[pos=.5] {\tiny Task 2};
    \draw[fill=green!20, thick] (0,0.6) rectangle (1.5,1.1) node[pos=.5] {\tiny Task 3};
    \node[right, align=left] at (1.7,1.4) {\small Едновременно\\[-2pt]\small изпълнение};
    
    % Concurrency/Async - RIGHT SIDE
    \node[font=\bfseries] at (7,2.8) {Асинхронност};
    % Row 1
    \draw[fill=blue!20, thick] (5.5,2.0) rectangle (6.3,2.4) node[pos=.5] {\tiny T1};
    \draw[fill=red!20, thick] (6.4,2.0) rectangle (7.0,2.4) node[pos=.5] {\tiny T2};
    \draw[fill=blue!20, thick] (7.1,2.0) rectangle (7.9,2.4) node[pos=.5] {\tiny T1};
    % Row 2
    \draw[fill=red!20, thick] (5.5,1.4) rectangle (6.1,1.8) node[pos=.5] {\tiny T2};
    \draw[fill=yellow!40, thick] (6.2,1.4) rectangle (7.0,1.8) node[pos=.5] {\tiny T3};
    \draw[fill=blue!20, thick] (7.1,1.4) rectangle (7.9,1.8) node[pos=.5] {\tiny T1};
    
    \node[right, align=left] at (8.1,1.7) {\small Чередуване};
\end{tikzpicture}
\end{center}

\vspace{0.3cm}
\textbf{Thread Pools:} истински паралелизъм (multiple cores) \\
\textbf{Coroutines:} кооперативна многозадачност (single core OK)
\end{frame}

\section{Thread Pools}

\subsection{Концепция}

\begin{frame}{Thread Pool: Концепция}
\begin{center}
\begin{tikzpicture}[scale=0.8,
    task/.style={rectangle, draw, fill=orange!30, minimum width=0.6cm, minimum height=0.4cm},
    thread/.style={rectangle, draw, fill=blue!20, minimum width=1.5cm, minimum height=0.6cm}]
    
    % Task Queue
    \node[font=\bfseries] at (-2,3.5) {Task Queue};
    \draw[thick] (-4,2) rectangle (1,3);
    \node[task] at (-3.5,2.5) {T1};
    \node[task] at (-2.6,2.5) {T2};
    \node[task] at (-1.7,2.5) {T3};
    \node[task] at (-0.8,2.5) {T4};
    \node[task] at (0.1,2.5) {T5};
    \node at (0.75,2.5) {...};
    
    % Thread Pool
    \node[font=\bfseries] at (4,3.5) {Thread Pool};
    \node[thread] (t1) at (4,2.7) {Worker 1};
    \node[thread] (t2) at (4,1.9) {Worker 2};
    \node[thread] (t3) at (4,1.1) {Worker 3};
    \node at (4,0.5) {...};
    
    % Arrows (must come after nodes are defined)
    \draw[-Latex, thick, red] (1,2.5) -- (t1.west);
    \draw[-Latex, thick, red] (1,2.5) -- (t2.west);
    \draw[-Latex, thick, red] (1,2.5) -- (t3.west);
\end{tikzpicture}
\end{center}

\textbf{Идея:} Фиксиран брой worker нишки, които обработват задачи от споделена опашка

\vspace{0.3cm}
\textbf{Предимства:}
\begin{itemize}
    \item Контрол върху броя нишки
    \item Преизползване на ресурси
    \item По-добра производителност
\end{itemize}
\end{frame}

\subsection{Защо е необходим?}

\begin{frame}[fragile]{Защо Thread Pool? Цената на създаване на нишки}

\textbf{Проблем:} Създаването и унищожаването на std::thread обекти е скъпа операция! \\

\begin{columns}
\column{0.45\textwidth}
\textbf{Наивен подход:}
\begin{lstlisting}[basicstyle=\ttfamily\tiny]
// Създаване на нова нишка 
// за ВСЯКА задача
for (auto& task : tasks) {
    std::thread t([&task]() {
        process(task);
    });
    t.detach(); // Опасно!
}

// Проблеми:
// 1. System call за създаване
// 2. Заделяне на stack памет
// 3. Context switching overhead
// 4. Унищожаване на ресурси
// 5. Няма контрол върху броя
\end{lstlisting}

\column{0.45\textwidth}
\textbf{Thread Pool подход:}
\begin{lstlisting}[basicstyle=\ttfamily\tiny]
// Еднократно създаване
ThreadPool pool(
    std::thread::
    hardware_concurrency()
);

// Многократно използване
for (auto& task : tasks) {
    pool.enqueue([&task]() {
        process(task);
    });
}
pool.wait_all();

// Предимства:
// 1. Нишките се създават веднъж
// 2. Преизползване на ресурси
// 3. Контролиран паралелизъм
// 4. По-добра cache locality
\end{lstlisting}
\end{columns}

\vspace{0.2cm}
\centering
\textbf{Benchmark:} Създаване на 1000 нишки $\approx$ 50-100ms, Thread Pool $\approx$ 1-2ms
\end{frame}

\begin{frame}{Overhead на създаване на нишки}
\begin{center}
\begin{tikzpicture}
    \begin{axis}[
        ybar,
        bar width=20pt,
        ylabel={Време (ms)},
        symbolic x coords={Създаване, Енкюиране в Pool},
        xtick=data,
        nodes near coords,
        nodes near coords align={vertical},
        ymin=0,
        ymax=120,
        width=10cm,
        height=6cm,
        legend style={at={(0.5,-0.15)}, anchor=north, legend columns=-1}
    ]
    \addplot coordinates {(Създаване,100) (Енкюиране в Pool,2)};
    \legend{1000 задачи}
    \end{axis}
\end{tikzpicture}
\end{center}

\textbf{Заключение:} Thread Pool е 50x по-бърз за множество малки задачи!
\end{frame}

\subsection{Предизвикателства}

\begin{frame}[fragile]{Предизвикателство: Синхронизация на опашката}

\textbf{Проблем:} Споделена опашка изисква lock за защита от race conditions

\begin{lstlisting}[basicstyle=\ttfamily\tiny]
class ThreadPool {
    std::queue<std::function<void()>> tasks;
    std::mutex queue_mutex;  // <-- КРИТИЧНА СЕКЦИЯ
    std::condition_variable condition;
    
    void worker_thread() {
        while (true) {
            std::function<void()> task;
            {
                std::unique_lock<std::mutex> lock(queue_mutex);  // LOCK!
                condition.wait(lock, [this] { return stop || !tasks.empty(); });
                if (stop && tasks.empty()) return;
                task = std::move(tasks.front());
                tasks.pop();
            }  // Unlock тук
            task();  // Изпълнение извън lock-а
        }
    }
};
\end{lstlisting}

\textbf{Bottleneck:} Всички нишки се конкурират за един mutex!
\end{frame}

\begin{frame}{Проблеми със standard mutex}
\begin{center}
\begin{tikzpicture}[scale=0.85]
    % Queue
    \node[rectangle, draw, thick, minimum width=3cm, minimum height=1cm, fill=yellow!20] (queue) at (0,2) {Task Queue};
    \node[rectangle, draw, thick, minimum width=3cm, minimum height=0.6cm, fill=red!30] (mutex) at (0,0.8) {Mutex (locked)};
    
    % Threads waiting
    \node[circle, draw, fill=blue!20] (t1) at (-3,-1) {T1};
    \node[circle, draw, fill=blue!20] (t2) at (-1.5,-1) {T2};
    \node[circle, draw, fill=green!20] (t3) at (0,-1) {T3};
    \node[circle, draw, fill=blue!20] (t4) at (1.5,-1) {T4};
    \node[circle, draw, fill=blue!20] (t5) at (3,-1) {T5};
    
    % Arrows
    \draw[-Latex, thick] (t1) -- (mutex);
    \draw[-Latex, thick] (t2) -- (mutex);
    \draw[-Latex, thick, green!60!black, line width=1.5pt] (t3) -- (mutex) node[midway, right] {\tiny owns};
    \draw[-Latex, thick] (t4) -- (mutex);
    \draw[-Latex, thick] (t5) -- (mutex);
    
    \node[below, red] at (0,-2) {Contention: 4 нишки чакат, само 1 работи!};
\end{tikzpicture}
\end{center}

\textbf{Последици:}
\begin{itemize}
    \item Context switching
    \item Cache invalidation
    \item Намалена throughput при много нишки
\end{itemize}
\end{frame}

\subsection{Lock-Free Queues}

\begin{frame}{Lock-Free структури: Концепция}

\textbf{Идея:} Използване на атомарни операции вместо mutex

\begin{columns}
\column{0.48\textwidth}
\textbf{Lock-based:}
\begin{itemize}
    \item[$\times$] Blocking
    \item[$\times$] Contention
    \item[$\times$] Priority inversion
    \item[$\times$] Deadlock риск
    \item[\checkmark] По-лесна имплементация
\end{itemize}

\column{0.48\textwidth}
\textbf{Lock-free:}
\begin{itemize}
    \item[\checkmark] Non-blocking
    \item[\checkmark] No contention
    \item[\checkmark] Wait-free progress
    \item[\checkmark] По-висока throughput
    \item[$\times$] Сложна имплементация
\end{itemize}
\end{columns}

\vspace{0.5cm}

\textbf{Ключови техники:}
\begin{itemize}
    \item Compare-And-Swap (CAS): \texttt{std::atomic::compare\_exchange\_weak}
    \item Memory ordering: \texttt{memory\_order\_acquire}, \texttt{memory\_order\_release}
    \item ABA problem решения (tagged pointers, hazard pointers)
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Atomic Memory Ordering: Защо е важно?}
\textbf{Файл:} \texttt{examples/07\_atomic\_memory\_ordering.cpp}

\textbf{Проблем:} Compiler и CPU могат да пренареждат инструкции за оптимизация!

\begin{lstlisting}[basicstyle=\ttfamily\tiny]
// Thread 1                    // Thread 2
data = 42;                     while (!ready.load()) {}
ready.store(true);             std::cout << data;  // Може да е неинициализиран!

// Без правилен memory order, Thread 2 може да види ready=true 
// ПРЕДИ data=42 заради reordering!
\end{lstlisting}

\textbf{Решение: Memory ordering constraints}
\begin{lstlisting}[basicstyle=\ttfamily\tiny]
// Thread 1 (Producer)
data = 42;
ready.store(true, std::memory_order_release);  // Гарантира: data пише ПРЕДИ ready

// Thread 2 (Consumer)
while (!ready.load(std::memory_order_acquire)) {}  // Синхронизира с release
std::cout << data;  // Сигурно е data == 42!
\end{lstlisting}

\textbf{Правило:} Release-Acquire паир създава happens-before relationship
\end{frame}

\begin{frame}[fragile]{Memory Ordering: Relaxed vs Acquire/Release}
\textbf{Файл:} \texttt{examples/07\_atomic\_memory\_ordering.cpp}
\begin{lstlisting}[basicstyle=\ttfamily\tiny]
std::atomic<int> counter{0};
std::atomic<bool> done{false};

void relaxed_increment() {
    for (int i = 0; i < 1000; ++i) {
        counter.fetch_add(1, std::memory_order_relaxed);  // Без синхронизация
    }
    done.store(true, std::memory_order_relaxed);
}

void acquire_release_increment() {
    for (int i = 0; i < 1000; ++i) {
        counter.fetch_add(1, std::memory_order_release);  // Гарантира видимост
    }
    done.store(true, std::memory_order_release);
}

// Main thread
void wait_for_completion() {
    while (!done.load(std::memory_order_acquire)) {}  // Синхронизира
    std::cout << "Counter: " << counter.load(std::memory_order_acquire);
}
\end{lstlisting}

\textbf{Relaxed:} Най-бързо, но без гаранции за ред \\
\textbf{Acquire/Release:} Синхронизация при минимален overhead
\end{frame}

\begin{frame}[fragile]{Lock-Free Queue: Концепция}
\begin{lstlisting}[basicstyle=\ttfamily\tiny]
template<typename T>
class LockFreeQueue {
    struct Node {
        std::shared_ptr<T> data;
        std::atomic<Node*> next;
        Node() : next(nullptr) {}
    };
    std::atomic<Node*> head;
    std::atomic<Node*> tail;
public:
    void enqueue(T value) {
        auto new_node = new Node();
        new_node->data = std::make_shared<T>(std::move(value));
        Node* old_tail = tail.load(std::memory_order_relaxed);
        while (!tail.compare_exchange_weak(old_tail, new_node, 
               std::memory_order_release, std::memory_order_relaxed)) {
            // Retry ако друга нишка промени tail
        }
        old_tail->next.store(new_node, std::memory_order_release);
    }
    std::shared_ptr<T> dequeue() {
        Node* old_head = head.load(std::memory_order_acquire);
        while (old_head && !head.compare_exchange_weak(old_head, 
               old_head->next.load(), std::memory_order_release)) {
            // Retry
        }
        return old_head ? old_head->data : nullptr;
    }
};
\end{lstlisting}
\end{frame}

\begin{frame}{Lock-Free vs Lock-Based: Performance}
\begin{center}
\begin{tikzpicture}
    \begin{axis}[
        xlabel={Брой нишки},
        ylabel={Operations/sec (millions)},
        xmin=1, xmax=16,
        ymin=0, ymax=100,
        xtick={1,2,4,8,16},
        ytick={0,20,40,60,80,100},
        legend pos=south east,
        width=10cm,
        height=6cm,
        grid=major
    ]
    \addplot[color=blue, mark=square, thick] coordinates {
        (1,40) (2,45) (4,50) (8,55) (16,60)
    };
    \addplot[color=red, mark=*, thick] coordinates {
        (1,40) (2,70) (4,85) (8,92) (16,95)
    };
    \legend{Lock-based, Lock-free}
    \end{axis}
\end{tikzpicture}
\end{center}

\textbf{Забележка:} Lock-free структури scaling-ват много по-добре!
\end{frame}

\subsection{Примерна имплементация}

\begin{frame}[fragile]{Thread Pool с Lock-Based Queue}
\begin{lstlisting}[basicstyle=\ttfamily\tiny]
class ThreadPool {
    std::vector<std::thread> workers;
    std::queue<std::function<void()>> tasks;
    std::mutex queue_mutex;
    std::condition_variable condition;
    bool stop = false;

public:
    ThreadPool(size_t threads) {
        for (size_t i = 0; i < threads; ++i) {
            workers.emplace_back([this] {
                while (true) {
                    std::function<void()> task;
                    {
                        std::unique_lock<std::mutex> lock(queue_mutex);
                        condition.wait(lock, [this] { 
                            return stop || !tasks.empty(); 
                        });
                        if (stop && tasks.empty()) return;
                        task = std::move(tasks.front());
                        tasks.pop();
                    }
                    task(); // Изпълнение извън lock-а
                }
            });
        }
    }
    // enqueue(), destructor...
};
\end{lstlisting}
\end{frame}

\begin{frame}[fragile]{Thread Pool: Пълен пример с използване}
\textbf{Файл:} \texttt{examples/01\_thread\_pool\_lock\_based.cpp}
\begin{lstlisting}[basicstyle=\ttfamily\tiny]
void cpu_intensive_task(int id, int duration_ms) {
    std::cout << "Task " << id << " starting (duration: " 
              << duration_ms << "ms)\n";
    std::this_thread::sleep_for(std::chrono::milliseconds(duration_ms));
    std::cout << "Task " << id << " completed\n";
}

int main() {
    const size_t num_threads = std::thread::hardware_concurrency();
    ThreadPool pool(num_threads);
    
    std::cout << "Creating thread pool with " << num_threads 
              << " workers\n";
    
    // Enqueue 20 tasks
    for (int i = 0; i < 20; ++i) {
        pool.enqueue([i]() {
            cpu_intensive_task(i, 100 + (i % 5) * 50);
        });
    }
    
    // Pool destructor waits for all tasks to complete
    std::cout << "All tasks completed!\n";
}
\end{lstlisting}
\end{frame}

\begin{frame}[fragile]{Lock-Free Queue: Пълна имплементация}
\textbf{Файл:} \texttt{examples/02\_lock\_free\_queue.cpp}
\begin{lstlisting}[basicstyle=\ttfamily\tiny]
template<typename T>
class LockFreeQueue {
private:
    struct Node {
        std::shared_ptr<T> data;
        std::atomic<Node*> next;
        Node() : next(nullptr) {}
        explicit Node(T value) : data(std::make_shared<T>(std::move(value))), next(nullptr) {}
    };
    std::atomic<Node*> head;
    std::atomic<Node*> tail;
public:
    void enqueue(T value) {
        Node* new_node = new Node(std::move(value));
        Node* old_tail = tail.load(std::memory_order_acquire);
        while (true) {
            Node* null_ptr = nullptr;
            if (old_tail->next.compare_exchange_weak(
                null_ptr, new_node,
                std::memory_order_release,
                std::memory_order_acquire)) {
                break;
            }
            old_tail = old_tail->next.load(std::memory_order_acquire);
        }
        tail.compare_exchange_strong(old_tail, new_node, std::memory_order_release, std::memory_order_acquire);
    }
};
\end{lstlisting}
\end{frame}

\begin{frame}[fragile]{Lock-Free Queue: Тестване с множество нишки}
\textbf{Файл:} \texttt{examples/02\_lock\_free\_queue.cpp}
\begin{lstlisting}[basicstyle=\ttfamily\tiny]
void producer(LockFreeQueue<int>& queue, int id, int count) {
    for (int i = 0; i < count; ++i) {
        int value = id * 1000 + i;
        queue.enqueue(value);
        std::cout << "Producer " << id << " enqueued: " << value << "\n";
    }
}

void consumer(LockFreeQueue<int>& queue, int id, int count) {
    int consumed = 0;
    while (consumed < count) {
        auto value = queue.dequeue();
        if (value) {
            std::cout << "Consumer " << id << " dequeued: " << *value << "\n";
            consumed++;
        }
    }
}

int main() {
    LockFreeQueue<int> queue;
    std::vector<std::thread> threads;
    
    // 3 producers, 3 consumers
    for (int i = 0; i < 3; ++i) {
        threads.emplace_back(producer, std::ref(queue), i, 5);
        threads.emplace_back(consumer, std::ref(queue), i, 5);
    }
    for (auto& t : threads) t.join();
}
\end{lstlisting}
\end{frame}

\section{Coroutines}

\subsection{Концепция}

\begin{frame}{Coroutines: Какво са?}

\textbf{Определение:} Функции, които могат да suspend-ват и resume-ват изпълнението си

\begin{center}
\begin{tikzpicture}[scale=0.9]
    % Timeline
    \draw[-Latex, thick] (0,0) -- (10,0) node[right] {Време};
    
    % Normal function
    \draw[fill=blue!30, thick] (0.5,1.5) rectangle (2,2) node[pos=.5] {\tiny Task A};
    \draw[fill=green!30, thick] (2.5,1.5) rectangle (4,2) node[pos=.5] {\tiny Task B};
    \draw[fill=red!30, thick] (4.5,1.5) rectangle (6,2) node[pos=.5] {\tiny Task C};
    \node[left] at (0,1.75) {Нормални функции:};
    
    % Coroutines
    \draw[fill=blue!30, thick] (0.5,0.3) rectangle (1.5,0.8) node[pos=.5] {\tiny A};
    \draw[fill=green!30, thick] (1.6,0.3) rectangle (2.6,0.8) node[pos=.5] {\tiny B};
    \draw[fill=blue!30, thick] (2.7,0.3) rectangle (3.7,0.8) node[pos=.5] {\tiny A};
    \draw[fill=red!30, thick] (3.8,0.3) rectangle (4.8,0.8) node[pos=.5] {\tiny C};
    \draw[fill=green!30, thick] (4.9,0.3) rectangle (5.9,0.8) node[pos=.5] {\tiny B};
    \draw[fill=blue!30, thick] (6.0,0.3) rectangle (7.0,0.8) node[pos=.5] {\tiny A};
    \node[left] at (0,0.55) {Coroutines:};
\end{tikzpicture}
\end{center}

\textbf{Ключови думи в C++20:}
\begin{itemize}
    \item \texttt{co\_await} – suspend и чакане на резултат
    \item \texttt{co\_yield} – връщане на междинна стойност
    \item \texttt{co\_return} – завършване на coroutine
\end{itemize}
\end{frame}

\begin{frame}{Threads vs Coroutines}
\begin{columns}
\column{0.48\textwidth}
\textbf{Threads (OS-level):}
\begin{itemize}
    \item Управлявани от ОС
    \item Преемптивен scheduling
    \item Тежки (MB stack)
    \item Context switch $\approx$1-10$\mu$s
    \item Паралелно изпълнение
    \item Използват множество ядра
\end{itemize}

\column{0.48\textwidth}
\textbf{Coroutines (user-level):}
\begin{itemize}
    \item Управлявани от програмата
    \item Кооперативен scheduling
    \item Леки (KB state)
    \item Context switch $\approx$10-100ns
    \item Конкурентно, не паралелно
    \item Едно ядро (освен ако...)
\end{itemize}
\end{columns}

\vspace{0.5cm}
\centering
\textbf{Идеално:} Coroutines за I/O, Threads за CPU-intensive работа
\end{frame}

\subsection{Как работят и защо са по-евтини?}

\begin{frame}{Coroutines: Механизъм на работа}

\textbf{Традиционна функция:}
\begin{itemize}
    \item Stack frame се създава при извикване
    \item Изпълнение до return
    \item Stack frame се унищожава
    \item Невъзможно повторно влизане
\end{itemize}

\vspace{0.3cm}

\textbf{Coroutine:}
\begin{itemize}
    \item Състоянието се съхранява в heap (coroutine frame)
    \item \texttt{co\_await} запазва локални променливи и позиция
    \item Контролът се връща на caller-а
    \item По-късно се resume-ва от същата позиция
\end{itemize}

\vspace{0.3cm}

\textbf{Защо са по-евтини от threads?}
\begin{enumerate}
    \item Без system calls за context switching
    \item Малко състояние (само локални променливи)
    \item Без thread stack (1-2 MB спестени)
    \item Compiler оптимизации (inline възможни)
\end{enumerate}
\end{frame}

\begin{frame}{Memory Layout: Thread vs Coroutine}
\begin{center}
\begin{tikzpicture}[scale=0.8]
    % Thread
    \node[font=\bfseries] at (-3,4) {Thread};
    \draw[fill=red!20, thick] (-5,0) rectangle (-3,3.5) node[pos=.5, rotate=90] {Stack (1-2 MB)};
    \draw[fill=blue!20, thick] (-2.8,0) rectangle (-1,0.5) node[pos=.5] {\tiny TCB};
    \node[below] at (-3,-0.5) {OS Managed};
    
    % Coroutine
    \node[font=\bfseries] at (3,4) {Coroutine};
    \draw[fill=green!20, thick] (1.0,2.5) rectangle (5.0,3.5) node[pos=.5] {Coroutine Frame};
    \node[below, font=\tiny] at (3,2.3) {Local vars + Resume point};
    \node[below, font=\tiny] at (3,2.0) {Typically < 1 KB};
    \draw[fill=yellow!20, thick] (1.5,1) rectangle (4.5,1.5) node[pos=.5] {\tiny Promise};
    \node[below] at (3,0.2) {Heap Allocated};
\end{tikzpicture}
\end{center}

\textbf{Резултат:} Можем да имаме милиони coroutines, но само стотици threads!
\end{frame}

\subsection{Предизвикателства}

\begin{frame}[fragile]{Предизвикателство: Dangling References и Pointers}

\textbf{ВАЖНО:} Локални променливи в coroutine са БЕЗОПАСНИ (в coroutine frame)!

\begin{lstlisting}[basicstyle=\ttfamily\tiny]
Task<int> safe_coroutine() {
    int local_var = 42;  // OK! В coroutine frame
    co_await some_async_operation();
    return local_var;  // БЕЗОПАСНО!
}
\end{lstlisting}

\textbf{Проблем 1: Указатели/референции към ВЪН от coroutine}

\begin{lstlisting}[basicstyle=\ttfamily\tiny]
Task<void> dangerous_coroutine(int* ptr) {  // Външен указател!
    co_await some_async_operation();
    *ptr = 42;  // ОПАСНО! ptr може да е невалиден
}

void caller() {
    int x = 10;
    auto task = dangerous_coroutine(&x);  // Адрес от caller stack
    // Ако caller приключи преди coroutine да resume-не...
    // x вече не съществува! -> Dangling pointer
}
\end{lstlisting}
\end{frame}

\begin{frame}[fragile]{Предизвикателство: Dangling References и Pointers}

\textbf{Проблем 2: Referencing локални променливи от caller; Lambda capture by reference}

\begin{lstlisting}[basicstyle=\ttfamily\tiny]
void caller() {
    std::vector<int> data = {1, 2, 3, 4, 5};
    
    auto task = [&data]() -> Task<void> {  // Capture by reference!
        co_await async_operation();
        // data е на stack-а на caller()
        // Ако caller() приключи преди resume -> CRASH!
        for (int x : data) { std::cout << x; }  // BUS ERROR!
    }();
    
    // caller() завършва, data се унищожава
    // но coroutine все още го реферира!
}
\end{lstlisting}

\textbf{Обобщение:}
\begin{itemize}
    \item[\checkmark] Локални променливи В coroutine $\rightarrow$ coroutine frame (SAFE)
    \item[$\times$] Указатели/референции КЪМ външни данни $\rightarrow$ dangling (DANGEROUS)
    \item[\checkmark] Използвайте capture by value: \texttt{[data]} вместо \texttt{[\&data]}
\end{itemize}
\end{frame}



\begin{frame}[fragile]{Решение: Как да поставим данни в coroutine frame?}

\textbf{Правило:} Всички променливи дефинирани в coroutine тяло автоматично се съхраняват в heap-allocated coroutine frame

\begin{columns}
\column{0.48\textwidth}
\textbf{Грешно (stack reference):}
\begin{lstlisting}[basicstyle=\ttfamily\tiny]
Task<void> bad_example() {
    std::string temp = "data";
    std::string& ref = temp;
    
    co_await switch_context();
    
    // ref може да е невалиден!
    std::cout << ref;
}

// Външна променлива
void caller() {
    int x = 42;
    auto task = [&x]() -> Task<void> {
        co_await something();
        // x е dangling reference!
        use(x);
    }();
}
\end{lstlisting}

\column{0.48\textwidth}
\textbf{Правилно (coroutine frame):}
\begin{lstlisting}[basicstyle=\ttfamily\tiny]
Task<void> good_example() {
    // Копие в coroutine frame
    std::string data = "data";
    
    co_await switch_context();
    
    // data е винаги валиден
    std::cout << data;
}

// Правилно capture
void caller() {
    int x = 42;
    auto task = [x]() -> Task<void> {
        // x е копирано (by value)
        co_await something();
        use(x); // SAFE!
    }();
}
\end{lstlisting}
\end{columns}

\vspace{0.3cm}
\textbf{Ключът:} Компилаторът автоматично премества локални променливи в coroutine frame. Проблемът идва от references/pointers към външни данни!
\end{frame}

\begin{frame}[fragile]{Техники за безопасно управление на данни}
\begin{columns}
\column{0.45\textwidth}
\textbf{1. Копиране вместо referencing}
\begin{lstlisting}[basicstyle=\ttfamily\tiny]
Task<void> process(std::string data) { 
    // by value = copy in frame
    co_await async_operation();
    use(data);  // Safe
}
\end{lstlisting}

\textbf{2. std::move за големи обекти}
\begin{lstlisting}[basicstyle=\ttfamily\tiny]
Task<void> process(std::vector<int> vec) {
    auto local_vec = std::move(vec); 
    // Move в coroutine frame
    co_await async_operation();
    use(local_vec);
}
\end{lstlisting}

\column{0.45\textwidth}
\textbf{3. shared\_ptr за споделени данни}
\begin{lstlisting}[basicstyle=\ttfamily\tiny]
Task<void> process(std::shared_ptr<BigData> data) {  
    // shared_ptr копира контролния блок, 
    // не данните
    co_await async_operation();
    use(*data);  // Safe - data е жив докато
                 // има reference
}
\end{lstlisting}

\textbf{4. Promise type с custom allocation}
\begin{lstlisting}[basicstyle=\ttfamily\tiny]
struct promise_type {
    void* operator new(size_t size) {
      // Custom allocator за coroutine frame
      return my_pool_allocator.allocate(size);
    }
    // Всички локални променливи + promise
    // отиват тук
};
\end{lstlisting}    
\end{columns}
\end{frame}

\begin{frame}[fragile]{Предизвикателство: Debugging и Stack Traces}

\textbf{Проблем:} Coroutines нямат традиционен stack trace

\begin{lstlisting}[basicstyle=\ttfamily\tiny]
Task<void> level3() {
    co_await std::suspend_always{};
    throw std::runtime_error("Error!");  // Къде е stack trace-а?
}

Task<void> level2() {
    co_await level3();
}

Task<void> level1() {
    co_await level2();
}

// При exception, debugger показва само текущата coroutine,
// не целия "async call stack"
\end{lstlisting}

\textbf{Решения:}
\begin{itemize}
    \item Използвайте coroutine-aware debuggers (LLDB, Visual Studio)
    \item Логване на входни/изходни точки
    \item Custom promise types с трacing
\end{itemize}
\end{frame}

\subsection{Примерна имплементация}

\begin{frame}[fragile]{Проста Coroutine имплементация (C++20)}
\textbf{Файл:} \texttt{examples/03\_basic\_coroutine.cpp}
\begin{lstlisting}[basicstyle=\ttfamily\tiny]
#include <coroutine>
#include <iostream>
template<typename T>
struct Task {
    struct promise_type {
        T value;
        Task get_return_object() { return Task{std::coroutine_handle<promise_type>::from_promise(*this)}; }
        std::suspend_never initial_suspend() { return {}; }
        std::suspend_always final_suspend() noexcept { return {}; }
        void unhandled_exception() { std::terminate(); }
        void return_value(T v) { value = v; }
    };
    std::coroutine_handle<promise_type> handle;
    T get() { return handle.promise().value; }
    ~Task() { if (handle) handle.destroy(); }
};
Task<int> async_computation() {
    std::cout << "Starting...\n";
    co_await std::suspend_always{};  // Suspend тук
    std::cout << "Resuming...\n";
    co_return 42;
}
int main() {
    auto task = async_computation();  // Стартира, спира на co_await
    task.handle.resume();  // Продължава изпълнението
    std::cout << "Result: " << task.get() << "\n";
}
\end{lstlisting}
\end{frame}

\begin{frame}[fragile]{Coroutine: Custom Awaitable}
\textbf{Файл:} \texttt{examples/03\_basic\_coroutine.cpp}
\begin{lstlisting}[basicstyle=\ttfamily\tiny]
// Awaitable за контрол на suspend/resume поведение
struct Suspend {
    bool await_ready() const noexcept { 
        return false;  // Винаги suspend
    }
    
    void await_suspend(std::coroutine_handle<>) const noexcept {
        std::cout << "  [Suspended]\n";
    }
    
    void await_resume() const noexcept {
        std::cout << "  [Resumed]\n";
    }
};

Task<int> compute_async(int a, int b) {
    std::cout << "Starting computation with " << a << " and " << b << "\n";
    
    co_await Suspend{};  // Първо suspend
    std::cout << "After first suspension\n";
    
    int intermediate = a + b;
    co_await Suspend{};  // Второ suspend
    
    int result = intermediate * 2;
    co_return result;
}
\end{lstlisting}
\end{frame}

\begin{frame}[fragile]{Реален пример: Async I/O с Coroutines}
\textbf{Файл:} \texttt{examples/09\_coroutine\_async\_io.cpp}
\begin{lstlisting}[basicstyle=\ttfamily\tiny]
Task<std::string> async_read_file(const std::string& filename) {
    // Simulate async file reading
    co_await async_open(filename);
    std::string content;
    while (true) {
        auto chunk = co_await async_read_chunk();
        if (chunk.empty()) break;
        content += chunk;
    }
    
    co_await async_close();
    co_return content;
}
Task<void> process_files() {
    // Множество паралелни четения (но в една нишка!)
    auto file1 = async_read_file("data1.txt");
    auto file2 = async_read_file("data2.txt");
    auto file3 = async_read_file("data3.txt");
    // Чакаме всички
    auto content1 = co_await file1;
    auto content2 = co_await file2;
    auto content3 = co_await file3;
    // Обработка...
    std::cout << "Total size: " << content1.size() + content2.size() + content3.size();
}
\end{lstlisting}

\textbf{Предимство:} Хиляди едновременни I/O операции без хиляди threads!
\end{frame}

\begin{frame}[fragile]{Coroutine: Event Loop и Async Task}
\textbf{Файл:} \texttt{examples/09\_coroutine\_async\_io.cpp}
\begin{lstlisting}[basicstyle=\ttfamily\tiny]
class EventLoop {
    std::queue<std::coroutine_handle<>> ready_queue;
    std::mutex queue_mutex;
public:
    void schedule(std::coroutine_handle<> handle) {
        std::lock_guard<std::mutex> lock(queue_mutex);
        ready_queue.push(handle);
    }
    void run() {
        while (true) {
            std::coroutine_handle<> handle;
            {
                std::lock_guard<std::mutex> lock(queue_mutex);
                if (ready_queue.empty()) break;
                handle = ready_queue.front();
                ready_queue.pop();
            }
            if (!handle.done()) handle.resume();
        }
    }
};
\end{lstlisting}

\textbf{Концепция:} Event loop управлява coroutines – suspend и resume без OS threads!
\end{frame}

\begin{frame}[fragile]{Coroutine: AsyncIO Awaitable}
\textbf{Файл:} \texttt{examples/09\_coroutine\_async\_io.cpp}
\begin{lstlisting}[basicstyle=\ttfamily\tiny]
// Awaitable за симулиране на async I/O
struct AsyncIO {
    std::string filename;
    int delay_ms;
    bool await_ready() { return false; }  // Винаги suspend
    void await_suspend(std::coroutine_handle<> h) {
        // Simulate async operation
        std::thread([h, delay = delay_ms]() {
            std::this_thread::sleep_for(std::chrono::milliseconds(delay));
            EventLoop::instance().schedule(h);  // Resume след завършване
        }).detach();
    }
    std::string await_resume() {
        return "Content from " + filename;
    }
};
AsyncTask<std::string> read_file_async(const std::string& file) {
    std::cout << "Starting read: " << file << "\n";
    auto content = co_await AsyncIO{file, 100};  // Suspend тук!
    std::cout << "Completed read: " << file << "\n";
    co_return content;
}
\end{lstlisting}
\end{frame}

\section{Publisher/Subscriber Pattern}

\subsection{Концепция}

\begin{frame}{Publisher/Subscriber: Design Pattern}
\begin{center}
\begin{tikzpicture}[scale=0.85, 
    publisher/.style={rectangle, draw, fill=green!20, minimum width=2cm, minimum height=1cm},
    subscriber/.style={rectangle, draw, fill=blue!20, minimum width=1.8cm, minimum height=0.8cm},
    broker/.style={ellipse, draw, fill=yellow!20, minimum width=2.5cm, minimum height=1.5cm, align=center}]
    
    \node[publisher] (pub1) at (0,3) {Publisher 1};
    \node[publisher] (pub2) at (0,1) {Publisher 2};
    
    \node[broker] (broker) at (4,2) {Event\\Broker};
    
    \node[subscriber] (sub1) at (8,3.5) {Subscriber A};
    \node[subscriber] (sub2) at (8,2) {Subscriber B};
    \node[subscriber] (sub3) at (8,0.5) {Subscriber C};
    
    \draw[-Latex, thick] (pub1) -- (broker) node[midway, above] {\tiny publish};
    \draw[-Latex, thick] (pub2) -- (broker) node[midway, below] {\tiny publish};
    
    \draw[-Latex, thick] (broker) -- (sub1) node[midway, above] {\tiny notify};
    \draw[-Latex, thick] (broker) -- (sub2) node[midway, above] {\tiny notify};
    \draw[-Latex, thick] (broker) -- (sub3) node[midway, below] {\tiny notify};
\end{tikzpicture}
\end{center}

\textbf{Определение:} Architectural pattern за асинхронна комуникация

\textbf{Компоненти:}
\begin{itemize}
    \item \textbf{Publisher} – генерира събития/съобщения
    \item \textbf{Subscriber} – регистрира интерес и обработва
    \item \textbf{Event Broker} – посредник (loose coupling)
\end{itemize}
\end{frame}

\begin{frame}{Защо Pub/Sub Pattern?}

\textbf{Проблеми на директната комуникация:}
\begin{itemize}
    \item Tight coupling между компоненти
    \item Трудно масштабиране
    \item Промяна в един компонент засяга много други
\end{itemize}

\vspace{0.4cm}

\textbf{Предимства на Pub/Sub:}
\begin{itemize}
    \item[\checkmark] \textbf{Loose coupling} – publishers не знаят за subscribers
    \item[\checkmark] \textbf{Scalability} – добавяне на subscribers без промяна
    \item[\checkmark] \textbf{Flexibility} – динамична (не)регистрация
    \item[\checkmark] \textbf{Асинхронност} – non-blocking communication
\end{itemize}

\vspace{0.4cm}

\textbf{vs Observer Pattern:}
\begin{itemize}
    \item Observer = synchronous, директна връзка
    \item Pub/Sub = asynchronous, чрез посредник (broker)
\end{itemize}
\end{frame}

\subsection{Приложения}

\begin{frame}{Къде се използва Pub/Sub?}

\textbf{Event-Driven Архитектури}
\begin{itemize}
    \item GUI Applications (button clicks, window events)
    \item Game engines (collision events, state changes)
\end{itemize}

\textbf{Microservices Communication}
\begin{itemize}
    \item Distributed systems (RabbitMQ, Apache Kafka)
    \item Service orchestration
\end{itemize}

\textbf{Real-Time Data Processing}
\begin{itemize}
    \item Stock market data feeds
    \item IoT sensor networks
    \item Log aggregation systems
\end{itemize}

\textbf{Reactive Programming}
\begin{itemize}
    \item RxCpp (Reactive Extensions)
    \item Async data streams
\end{itemize}
\end{frame}

\begin{frame}{Примери от практиката}
\begin{columns}
\column{0.48\textwidth}
\textbf{Financial Trading System:}
\begin{enumerate}
    \item Market data feed (publisher)
    \item Risk engine (subscriber)
    \item Trading strategies (subscribers)
    \item Compliance monitor (subscriber)
    \item Logging system (subscriber)
\end{enumerate}

\textit{Всички компоненти получават същите данни, но ги обработват различно}

\column{0.48\textwidth}
\textbf{IoT Smart Home:}
\begin{enumerate}
    \item Temperature sensor (publisher)
    \item Heating system (subscriber)
    \item Mobile app (subscriber)
    \item Data logger (subscriber)
    \item Alert system (subscriber)
\end{enumerate}

\textit{Едно събитие тригерва множество реакции}
\end{columns}
\end{frame}

\subsection{Предизвикателства}

\begin{frame}{Предизвикателство 1: Гаранции за доставка}

\textbf{Проблем:} Какво ако subscriber не получи съобщението?

\vspace{0.3cm}

\textbf{Опции за доставка:}
\begin{enumerate}
    \item \textbf{At-most-once} – "fire and forget"
    \begin{itemize}
        \item Най-бързо, но може да се загуби
        \item Подходящо за некритични данни (metrics)
    \end{itemize}
    
    \item \textbf{At-least-once} – retry при неуспех
    \begin{itemize}
        \item Може да има дубликати
        \item Нуждае се от idempotent обработка
    \end{itemize}
    
    \item \textbf{Exactly-once} – гарантирана еднократна доставка
    \begin{itemize}
        \item Най-сложно, изисква транзакции
        \item Критични системи (payments, medical)
    \end{itemize}
\end{enumerate}

\vspace{0.3cm}
\textbf{Trade-off:} Надеждност vs Performance
\end{frame}

\begin{frame}{Предизвикателство 2: Backpressure}

\textbf{Проблем:} Publisher генерира събития по-бързо, отколкото subscribers могат да обработят

\begin{center}
\begin{tikzpicture}[scale=0.8]
    % Fast publisher
    \node[rectangle, draw, fill=red!40] at (-0.75,2) {Fast Publisher};
    \draw[-Latex, very thick, red] (1,2) -- (3,2) node[midway, above] {\tiny 10000 msg/s};
    
    % Queue
    \node[rectangle, draw, fill=yellow!30, minimum width=2cm, minimum height=1.5cm] (queue) at (4.5,2) {};
    \foreach \y in {1.5,1.7,1.9,2.1,2.3,2.5,2.7} {
        \draw[fill=orange!20] (3.7,\y) rectangle (5.3,\y+0.15);
    }
    \node[above] at (4.5,2.8) {\tiny Queue};
    \node[below, red] at (4.5,1.2) {\tiny OVERFLOW!};
    
    % Slow subscriber
    \node[rectangle, draw, fill=blue!20] at (9,2) {Slow Subscriber};
    \draw[-Latex, thick, blue] (6,2) -- (7,2) node[midway, above] {\tiny 100 msg/s};
\end{tikzpicture}
\end{center}

\textbf{Решения:}
\begin{itemize}
    \item Buffering с bounded queue
    \item Dropping (отпадане на стари съобщения)
    \item Throttling (забавяне на publisher-а)
    \item Паралелизация на subscribers (нашата тема!)
\end{itemize}
\end{frame}

\begin{frame}{Предизвикателство 3: Ordering}

\textbf{Проблем:} Запазване на реда на съобщенията при паралелна обработка\\

\begin{lstlisting}[basicstyle=\ttfamily\tiny, language=C++]
// Publisher изпраща: Message 1, 2, 3
publisher.publish(msg1);
publisher.publish(msg2);
publisher.publish(msg3);

// Subscriber с thread pool може да получи: 2, 1, 3
// заради паралелна обработка!
\end{lstlisting}

\textbf{Решения:}
\begin{enumerate}
    \item \textbf{Single-threaded processing} – губим паралелизъм
    \item \textbf{Partition-based} – групи съобщения с гарантиран ред
    \item \textbf{Sequence numbers} – преподреждане след обработка
    \item \textbf{Per-key ordering} – само свързани съобщения се подреждат
\end{enumerate}
\end{frame}

\subsection{Примерна имплементация}

\begin{frame}[fragile]{Проста Pub/Sub имплементация}
\textbf{Файл:} \texttt{examples/04\_pubsub\_synchronous.cpp}
\begin{lstlisting}[basicstyle=\ttfamily\tiny]
template<typename Event>
class EventBroker {
    using Subscriber = std::function<void(const Event&)>;
    using SubscriberId = size_t;
    std::unordered_map<SubscriberId, Subscriber> subscribers;
    std::mutex mutex;
    SubscriberId next_id = 0;
public:
    SubscriberId subscribe(Subscriber&& callback) {
        std::lock_guard<std::mutex> lock(mutex);
        auto id = next_id++;
        subscribers[id] = std::move(callback);
        return id;
    }
    void unsubscribe(SubscriberId id) {
        std::lock_guard<std::mutex> lock(mutex);
        subscribers.erase(id);
    }
    void publish(const Event& event) {
        std::lock_guard<std::mutex> lock(mutex);
        for (auto& [id, subscriber] : subscribers) {
            subscriber(event);  // Синхронно извикване
        }
    }
};
\end{lstlisting}

\textbf{Проблем:} publish() блокира до обработка на всички subscribers!
\end{frame}

\begin{frame}[fragile]{Pub/Sub Synchronous: Smart Home пример}
\textbf{Файл:} \texttt{examples/04\_pubsub\_synchronous.cpp}
\begin{lstlisting}[basicstyle=\ttfamily\tiny]
struct TemperatureEvent { double temperature; std::string sensor_id; };
class HeatingSystem {
public:
    void on_temperature(const TemperatureEvent& event) {
        std::cout << "  [HeatingSystem] Temperature from " << event.sensor_id 
                  << ": " << event.temperature << " C";
        if (event.temperature < 18.0) std::cout << " - HEATING ON";
        else if (event.temperature > 24.0) std::cout << " - HEATING OFF";
        std::cout << "\n";
    }
};
int main() {
    EventBroker<TemperatureEvent> broker;
    HeatingSystem heating;
    MobileApp app;
    DataLogger logger;
    // Subscribe
    broker.subscribe([&](const auto& e) { heating.on_temperature(e); });
    broker.subscribe([&](const auto& e) { app.on_temperature(e); });
    broker.subscribe([&](const auto& e) { logger.log_temperature(e); });
    // Publish events
    broker.publish({20.5, "Living Room"});
    broker.publish({16.2, "Bedroom"});
}
\end{lstlisting}
\end{frame}

\begin{frame}[fragile]{Асинхронна имплементация с Thread Pool}
\textbf{Файл:} \texttt{examples/05\_pubsub\_async\_threadpool.cpp}
\begin{lstlisting}[basicstyle=\ttfamily\tiny]
template<typename Event>
class AsyncEventBroker {
    using Subscriber = std::function<void(const Event&)>;
    std::vector<Subscriber> subscribers;
    ThreadPool pool;
    std::mutex mutex;
public:
    AsyncEventBroker(size_t num_threads = std::thread::hardware_concurrency())
        : pool(num_threads) {}
    void subscribe(Subscriber&& callback) {
        std::lock_guard<std::mutex> lock(mutex);
        subscribers.push_back(std::move(callback));
    }
    void publish(const Event& event) {
        std::lock_guard<std::mutex> lock(mutex);
        // Всеки subscriber се обработва в отделна задача
        for (auto& subscriber : subscribers) {
            pool.enqueue([subscriber, event]() {
                subscriber(event);  // Паралелно изпълнение!
            });
        }
    }  // publish() не чака обработката
};
\end{lstlisting}

\textbf{Предимство:} Non-blocking publish(), паралелна обработка!
\end{frame}

\begin{frame}[fragile]{Pub/Sub с Thread Pool: Практически пример}
\textbf{Файл:} \texttt{examples/05\_pubsub\_async\_threadpool.cpp}
\begin{lstlisting}[basicstyle=\ttfamily\tiny]
struct StockPrice { std::string symbol; double price; };
int main() {
    ThreadPool pool(4);
    AsyncEventBroker<StockPrice> broker(pool);
    // Subscribe различни компоненти
    broker.subscribe([](const StockPrice& event) {
        std::cout << "[RiskEngine] Processing " << event.symbol 
                  << " @ " << event.price << "\n";
        std::this_thread::sleep_for(std::chrono::milliseconds(50));
    });
    broker.subscribe([](const StockPrice& event) {
        std::cout << "[TradingStrategy] Analyzing " << event.symbol 
                  << " @ " << event.price << "\n";
        std::this_thread::sleep_for(std::chrono::milliseconds(30));
    });
    // Publish 10 events
    for (int i = 0; i < 10; ++i) {
        broker.publish({"AAPL", 150.0 + i});
        std::cout << "[Publisher] Published event " << i << "\n";
    }
}
\end{lstlisting}
\end{frame}

\begin{frame}[fragile]{Lock-Free Pub/Sub с RCU Pattern}
\textbf{Файл:} \texttt{examples/06\_pubsub\_lockfree\_rcu.cpp}
\begin{lstlisting}[basicstyle=\ttfamily\tiny]
template<typename Event>
class RCUEventBroker {
    struct SubscriberNode {
        std::function<void(const Event&)> callback;
        std::shared_ptr<SubscriberNode> next;
    };
    std::shared_ptr<SubscriberNode> head;
public:
    // Lock-free subscription using Compare-And-Swap
    void subscribe(std::function<void(const Event&)> callback) {
        auto new_node = std::make_shared<SubscriberNode>();
        new_node->callback = std::move(callback);
        auto old_head = std::atomic_load(&head);
        do {
            new_node->next = old_head;
        } while (!std::atomic_compare_exchange_weak(
            &head, &old_head, new_node));
    }
    // Wait-free publish (read-only operation)
    void publish(const Event& event) {
        auto node = std::atomic_load(&head);
        while (node) {
            node->callback(event);
            node = node->next;
        }
    }
};
\end{lstlisting}
\end{frame}

\begin{frame}[fragile]{RCU Pattern: Тестване на конкурентност}
\textbf{Файл:} \texttt{examples/06\_pubsub\_lockfree\_rcu.cpp}
\begin{lstlisting}[basicstyle=\ttfamily\tiny]
struct SensorReading { int sensor_id; double value; long timestamp; };
void subscriber_thread(RCUEventBroker<SensorReading>& broker, int id, int count) {
    for (int i = 0; i < count; ++i) {
        broker.subscribe([id, i](const SensorReading& event) {
            std::cout << "[Subscriber " << id << "-" << i 
                      << "] Sensor " << event.sensor_id 
                      << ": " << event.value << "\n";
        });
    }
}
void publisher_thread(RCUEventBroker<SensorReading>& broker, int id, int count) {
    for (int i = 0; i < count; ++i) {
        broker.publish({id, 25.0 + i * 0.5, 
                       std::chrono::system_clock::now().time_since_epoch().count()});
    }
}
int main() {
    RCUEventBroker<SensorReading> broker;
    std::vector<std::thread> threads;
    // 5 concurrent subscribers
    for (int i = 0; i < 5; ++i)
        threads.emplace_back(subscriber_thread, std::ref(broker), i, 2);
    // 3 concurrent publishers
    for (int i = 0; i < 3; ++i)
        threads.emplace_back(publisher_thread, std::ref(broker), i, 10);
    for (auto& t : threads) t.join();
}
\end{lstlisting}
\end{frame}

\subsection{Паралелизирано разпращане}

\begin{frame}{Паралелизация на subscriber dispatch}

\textbf{Проблем:} Наивната имплементация има serialization bottleneck

\begin{center}
\begin{tikzpicture}[scale=0.75]
    % Naive approach
    \node[font=\bfseries] at (0,4) {Наивен подход};
    \node[rectangle, draw, fill=red!20] (pub) at (0,3) {Publisher};
    \node[rectangle, draw, fill=yellow!30] (broker) at (0,1.8) {Broker (mutex)};
    
    \draw[-Latex, thick] (pub) -- (broker);
    \draw[-Latex, thick] (broker) -- ++(3.0,1.2) node[right] {\tiny Sub1};
    \draw[-Latex, thick] (broker) -- ++(3.0,0.0) node[right] {\tiny Sub2};
    \draw[-Latex, thick] (broker) -- ++(3.0,-1.2) node[right] {\tiny Sub3};
    \node[below, red] at (0,0.8) {\tiny Serialization!};
    
    % Optimized approach
    \node[font=\bfseries] at (7,4) {Оптимизиран подход};
    \node[rectangle, draw, fill=red!20] (pub2) at (7,3) {Publisher};
    \node[rectangle, draw, fill=green!30] (broker2) at (7,1.8) {Lock-free Broker};
    
    \draw[-Latex, thick, green!60!black] (pub2) -- (broker2);
    \draw[-Latex, thick, green!60!black] (broker2) -- ++(3.5,1.2) node[right] {\tiny Sub1};
    \draw[-Latex, thick, green!60!black] (broker2) -- ++(3.5,0.0) node[right] {\tiny Sub2};
    \draw[-Latex, thick, green!60!black] (broker2) -- ++(3.5,-1.2) node[right] {\tiny Sub3};
    \node[below, green!60!black] at (7,0.8) {\tiny Паралелно!};
\end{tikzpicture}
\end{center}

\textbf{Техники за оптимизация:}
\begin{itemize}
    \item Lock-free subscriber list (RCU - Read-Copy-Update)
    \item Per-subscriber queue вместо centralized
    \item Wait-free publish операции
    \item Batch processing на множество събития
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Сравнителна графика: Всички имплементации}
\begin{tikzpicture}
    \begin{axis}[
        width=\textwidth,
        height=6.5cm,
        xlabel={Брой абонати},
        ylabel={Време (ns)},
        xmode=log,
        ymode=log,
        legend style={at={(0.5,-0.22)}, anchor=north, legend columns=4, font=\tiny},
        grid=major,
        mark options={solid},
        tick label style={font=\tiny},
        label style={font=\small}
    ]
    
        %% PubSub Sync
        \addplot+[mark=*, thick] coordinates {
            (1, 0.001678) (10, 0.001920) (100, 0.001732) (1000, 0.001138) (100000, 0.001067)
        };
        \addlegendentry{PubSub Sync}
        
        %% StdAsync NoWait
        \addplot+[mark=square*, thick] coordinates {
            (1, 0.003285) (10, 0.012376) (100, 0.008696) (1000, 0.008552) (100000, 0.006913)
        };
        \addlegendentry{StdAsync NoWait}
        
        %% std::exec seq
        \addplot+[mark=triangle*, thick] coordinates {
            (1, 0.001199) (10, 0.001584) (100, 0.001345) (1000, 0.000561) (100000, 0.001098)
        };
        \addlegendentry{std::exec seq}
        
        %% std::exec par
        \addplot+[mark=diamond*, thick] coordinates {
            (1, 0.001546) (10, 0.001907) (100, 0.001481) (1000, 0.000933) (100000, 0.001179)
        };
        \addlegendentry{std::exec par}
        
        %% std::exec par_unseq
        \addplot+[mark=star, thick] coordinates {
            (1, 0.001632) (10, 0.000363) (100, 0.001491) (1000, 0.000731) (100000, 0.001319)
        };
        \addlegendentry{std::exec par\_unseq}
        
        %% std::exec unseq
        \addplot+[mark=halfcircle*, thick] coordinates {
            (1, 0.001447) (10, 0.000889) (100, 0.000893) (1000, 0.000897) (100000, 0.001263)
        };
        \addlegendentry{std::exec unseq}
        
        %% TBB
        \addplot+[mark=+, thick] coordinates {
            (1, 0.000004) (10, 0.000753) (100, 0.002422) (1000, 0.001643) (100000, 0.002144)
        };
        \addlegendentry{TBB}
        
        %% Boost
        \addplot+[mark=x, thick] coordinates {
            (1, 0.000820) (10, 0.001429) (100, 0.001530) (1000, 0.000659) (100000, 0.001000)
        };
        \addlegendentry{Boost}
        
        %% Qt
        \addplot+[mark=otimes*, thick] coordinates {
            (1, 0.001374) (10, 0.001596) (100, 0.000879) (1000, 0.001814) (100000, 0.001157)
        };
        \addlegendentry{Qt}
        
        %% Python
        \addplot+[mark=triangle, thick] coordinates {
            (1, 17147.482064) (10, 15299.786308) (100, 18820.008432) (1000, 13669.851635) (100000, 15613.057011)
        };
        \addlegendentry{Python}
        
        %% NodeJS
        \addplot+[mark=diamond, thick] coordinates {
            (1, 4011.392354) (10, 246244.767299) (100, 281627.468817) (1000, 795439.269405) (100000, 1174037.044250)
        };
        \addlegendentry{NodeJS}
    
    \end{axis}
\end{tikzpicture}
\end{frame}

\begin{frame}[fragile]{Сравнителна графика: C++ имплементации}
\begin{columns}[T]
\column{0.62\textwidth}
\begin{tikzpicture}
    \begin{axis}[
        width=\textwidth,
        height=6.5cm,
        xlabel={Брой абонати},
        ylabel={Време (ns)},
        xmode=log,
        ymode=log,
        legend style={at={(0.5,-0.22)}, anchor=north, legend columns=3, font=\tiny},
        grid=major,
        mark options={solid},
        tick label style={font=\tiny},
        label style={font=\small}
    ]
    
        %% PubSub Sync
        \addplot+[mark=*, thick] coordinates {
            (1, 0.001678) (10, 0.001920) (100, 0.001732) (1000, 0.001138) (100000, 0.001067)
        };
        \addlegendentry{PubSub Sync}
        
        %% StdAsync NoWait
        \addplot+[mark=square*, thick] coordinates {
            (1, 0.003285) (10, 0.012376) (100, 0.008696) (1000, 0.008552) (100000, 0.006913)
        };
        \addlegendentry{StdAsync NoWait}
        
        %% std::exec seq
        \addplot+[mark=triangle*, thick] coordinates {
            (1, 0.001199) (10, 0.001584) (100, 0.001345) (1000, 0.000561) (100000, 0.001098)
        };
        \addlegendentry{std::exec seq}
        
        %% std::exec par
        \addplot+[mark=diamond*, thick] coordinates {
            (1, 0.001546) (10, 0.001907) (100, 0.001481) (1000, 0.000933) (100000, 0.001179)
        };
        \addlegendentry{std::exec par}
        
        %% std::exec par_unseq
        \addplot+[mark=star, thick] coordinates {
            (1, 0.001632) (10, 0.000363) (100, 0.001491) (1000, 0.000731) (100000, 0.001319)
        };
        \addlegendentry{std::exec par\_unseq}
        
        %% std::exec unseq
        \addplot+[mark=halfcircle*, thick] coordinates {
            (1, 0.001447) (10, 0.000889) (100, 0.000893) (1000, 0.000897) (100000, 0.001263)
        };
        \addlegendentry{std::exec unseq}
        
        %% TBB
        \addplot+[mark=+, thick] coordinates {
            (1, 0.000004) (10, 0.000753) (100, 0.002422) (1000, 0.001643) (100000, 0.002144)
        };
        \addlegendentry{TBB}
        
        %% Boost
        \addplot+[mark=x, thick] coordinates {
            (1, 0.000820) (10, 0.001429) (100, 0.001530) (1000, 0.000659) (100000, 0.001000)
        };
        \addlegendentry{Boost}
        
        %% Qt
        \addplot+[mark=otimes*, thick] coordinates {
            (1, 0.001374) (10, 0.001596) (100, 0.000879) (1000, 0.001814) (100000, 0.001157)
        };
        \addlegendentry{Qt}
    
    \end{axis}
\end{tikzpicture}

\column{0.38\textwidth}
\textbf{\tiny oneTBB:}
\begin{lstlisting}[basicstyle=\ttfamily\tiny, numbers=none, frame=none, backgroundcolor=\color{gray!5}]
template<auto Event, typename... Args>
bool Publisher::emit_tbb_async(Args&&... args) {
 auto* handler = get_handler<Event>();
 tbb::parallel_for_each(
  handler->callbacks.begin(),
  handler->callbacks.end(),
  [&](const auto& cb) {
   cb(std::forward<Args>(args)...);
  });
 return true;
}
\end{lstlisting}
\textbf{\tiny std::execution:}
\begin{lstlisting}[basicstyle=\ttfamily\tiny, numbers=none, frame=none, backgroundcolor=\color{gray!5}]
template<auto Event, typename... Args>
bool Publisher::emit_async(std::execution::parallel_policy policy, Args&&... args) {
 auto* handler = get_handler<Event>();
 std::for_each(policy,
  handler->callbacks.begin(),
  handler->callbacks.end(),
  [&](const auto& cb) {
    cb(std::forward<Args>(args)...);
  });
 return true;
}
\end{lstlisting}
\end{columns}
\end{frame}

\begin{frame}[fragile]{Паралелни алгоритми: oneTBB пример}
\textbf{Файл:} \texttt{examples/08\_onetbb\_examples.cpp}

\textbf{oneTBB (Threading Building Blocks):} High-level паралелни алгоритми

\begin{lstlisting}[basicstyle=\ttfamily\tiny]
#include <tbb/parallel_for.h>
#include <tbb/parallel_reduce.h>
#include <vector>
void parallel_for_example() {
    std::vector<int> data(1000000);
    tbb::parallel_for(tbb::blocked_range<size_t>(0, data.size()), [&](const tbb::blocked_range<size_t>& r) {
            for (size_t i = r.begin(); i < r.end(); ++i) {
                data[i] = i * i;  // Всеки елемент се обработва паралелно
            }
        }
    );
}
int parallel_reduce_example() {
    std::vector<int> data(1000000, 1);
    // Паралелно сумиране
    int sum = tbb::parallel_reduce(
        tbb::blocked_range<size_t>(0, data.size()), 0,  // Начална стойност
        [&](const tbb::blocked_range<size_t>& r, int init) {
            for (size_t i = r.begin(); i < r.end(); ++i)
                init += data[i];
            return init;
        }, std::plus<int>()  // Combine функция
    );
    return sum;
}
\end{lstlisting}
\end{frame}

\section{Комбиниране на техниките}

\begin{frame}{Интеграция: Thread Pool + Coroutines + Pub/Sub}
\begin{center}
\begin{tikzpicture}[scale=0.7,
    component/.style={rectangle, draw, rounded corners, minimum width=2.2cm, minimum height=0.8cm}]
    
    \node[component, fill=green!20] (source) at (0,4) {Data Source};
    \node[component, fill=yellow!20] (pub) at (0,2.5) {Publisher};
    \node[component, fill=orange!20] (broker) at (5,2.5) {Event Broker};
    
    \node[component, fill=red!20] (pool) at (5,0.5) {Thread Pool};
    
    \node[component, fill=blue!20, align=center] (sub1) at (10,5.5) {Subscriber 1\\Coroutine};
    \node[component, fill=blue!20, align=center] (sub2) at (10,3.5) {Subscriber 2\\CPU-bound};
    \node[component, fill=blue!20, align=center] (sub3) at (10,1.5) {Subscriber 3\\I/O-bound};
    
    \draw[-Latex, thick] (source) -- (pub);
    \draw[-Latex, thick] (pub) -- (broker) node[midway, above] {\tiny publish};
    \draw[-Latex, thick] (broker) -- (pool) node[midway, right] {\tiny dispatch};
    
    \draw[-Latex, thick, green!60!black] (pool.east) -- ++(1,0) |- (sub1.west);
    \draw[-Latex, thick, red] (pool.east) -- ++(1,0) |- (sub2.west);
    \draw[-Latex, thick, blue] (pool.east) -- ++(1,0) |- (sub3.west);
\end{tikzpicture}
\end{center}

\textbf{Hybrid подход:}
\begin{itemize}
    \item Thread Pool за паралелна обработка (CPU-intensive)
    \item Coroutines за I/O операции (networking, disk)
    \item Pub/Sub за декуплиране и организация
\end{itemize}
\end{frame}

\begin{frame}{Кога какво да използваме?}
\begin{table}
\centering
\small
\begin{tabular}{|l|l|l|}
\hline
\textbf{Задача} & \textbf{Техника} & \textbf{Защо?} \\
\hline
CPU-intensive & Thread Pool & Използва всички ядра \\
I/O операции & Coroutines & Ниски overhead, милиони connections \\
Event routing & Pub/Sub & Loose coupling \\
High-throughput & Lock-free + Pool & Минимизира contention \\
Mixed workload & Hybrid & Комбинира силни страни \\
\hline
\end{tabular}
\end{table}

\vspace{0.5cm}

\textbf{Практически съвет:}
\begin{enumerate}
    \item Измерете bottleneck-овете (профилиране!)
    \item Не оптимизирайте преждевременно
    \item Комбинирайте техники според нуждите
\end{enumerate}
\end{frame}

\begin{frame}[fragile]{Hybrid Approach: Lock-Free SPSC Queue}
\textbf{Файл:} \texttt{examples/10\_hybrid\_approach.cpp}
\begin{lstlisting}[basicstyle=\ttfamily\tiny]
template<typename T, size_t Size = 1024>
class SPSCQueue {
    struct alignas(64) {  // Cache line alignment
        std::atomic<size_t> value{0};
    } head, tail;
    T buffer[Size];
public:
    bool enqueue(const T& item) {
        size_t current_tail = tail.value.load(std::memory_order_relaxed);
        size_t next_tail = (current_tail + 1) % Size;
        if (next_tail == head.value.load(std::memory_order_acquire))
            return false;  // Queue full
        buffer[current_tail] = item;
        tail.value.store(next_tail, std::memory_order_release);
        return true;
    }
    bool dequeue(T& item) {
        size_t current_head = head.value.load(std::memory_order_relaxed);
        if (current_head == tail.value.load(std::memory_order_acquire))
            return false;  // Queue empty
        item = buffer[current_head];
        head.value.store((current_head + 1) % Size, std::memory_order_release);
        return true;
    }
};
\end{lstlisting}
\end{frame}

\begin{frame}[fragile]{Hybrid: Lock-Free Thread Pool с Per-Worker Queues}
\textbf{Файл:} \texttt{examples/10\_hybrid\_approach.cpp}
\begin{lstlisting}[basicstyle=\ttfamily\tiny]
class Worker {
    std::thread thread;
    SPSCQueue<std::function<void()>> tasks;  // Lock-free queue!
    std::atomic<bool> running{true};
    void run() {
        std::function<void()> task;
        while (running.load(std::memory_order_acquire)) {
            if (tasks.dequeue(task))
                task();
            else
                std::this_thread::yield();
        }
    }
public:
    Worker() : thread(&Worker::run, this) {}
    bool submit(std::function<void()>&& task) {
        return tasks.enqueue(task);
    }
};
class LockFreeThreadPool {
    std::vector<std::unique_ptr<Worker>> workers;
    std::atomic<size_t> next_worker{0};
public:
    void submit(std::function<void()>&& task) {
        size_t worker_id = next_worker.fetch_add(1) % workers.size();
        workers[worker_id]->submit(std::move(task));
    }
};
\end{lstlisting}
\end{frame}

\begin{frame}[fragile]{Hybrid System: Интеграция на всичко}
\textbf{Файл:} \texttt{examples/10\_hybrid\_approach.cpp}
\begin{lstlisting}[basicstyle=\ttfamily\tiny]
struct Task { int id; std::string data; };

int main() {
    LockFreeThreadPool pool(4);  // 4 workers с lock-free queues
    RCUEventBroker<Task> broker; // Lock-free pub/sub
    
    // Subscribe processing units
    broker.subscribe([&pool](const Task& task) {
        pool.submit([task]() {
            // CPU-intensive обработка в thread pool
            std::cout << "[Worker] Processing task " << task.id << "\n";
            std::this_thread::sleep_for(std::chrono::milliseconds(10));
        });
    });
    
    // High-throughput event generation
    std::thread publisher([&broker]() {
        for (int i = 0; i < 1000; ++i) {
            broker.publish({i, "Data-" + std::to_string(i)});
        }
    });
    
    publisher.join();
    std::this_thread::sleep_for(std::chrono::seconds(2));  // Wait for processing
    std::cout << "All tasks processed!\n";
}
\end{lstlisting}

\textbf{Предимства:} Wait-free publish + Lock-free queues + Паралелна обработка!
\end{frame}

\section{Заключение}

\begin{frame}{Преглед на примерите}
\textbf{Всички примери са налични в папка \texttt{examples/}}

\begin{table}
\centering
\footnotesize
\begin{tabular}{|l|l|}
\hline
\textbf{Пример} & \textbf{Секция в лекцията} \\
\hline
01\_thread\_pool\_lock\_based.cpp & Thread Pools – Lock-Based \\
02\_lock\_free\_queue.cpp & Lock-Free Queues \\
03\_basic\_coroutine.cpp & Coroutines – Basic \\
04\_pubsub\_synchronous.cpp & Publisher/Subscriber – Sync \\
05\_pubsub\_async\_threadpool.cpp & Publisher/Subscriber – Async \\
06\_pubsub\_lockfree\_rcu.cpp & Publisher/Subscriber – Lock-Free \\
07\_atomic\_memory\_ordering.cpp & Lock-Free – Memory Ordering \\
08\_onetbb\_examples.cpp & Паралелни алгоритми – oneTBB \\
09\_coroutine\_async\_io.cpp & Coroutines – Async I/O \\
10\_hybrid\_approach.cpp & Комбиниране на техниките \\
\hline
\end{tabular}
\end{table}

\vspace{0.3cm}
\textbf{Компилиране:}
\begin{itemize}
    \item \texttt{cd examples \&\& mkdir build \&\& cd build}
    \item \texttt{cmake .. \&\& cmake $-$$-$build .}
    \item Всеки пример е отделен executable
\end{itemize}
\end{frame}

\begin{frame}{Обобщение}
\textbf{Какво научихме днес:}

\begin{enumerate}
    \item \textbf{Thread Pools}
    \begin{itemize}
        \item Преизползване на нишки за ефективност
        \item Lock-based vs lock-free имплементации
        \item Цената на създаване на threads (50-100x!)
    \end{itemize}
    
    \item \textbf{Coroutines}
    \begin{itemize}
        \item Леки, кооперативни задачи
        \item Идеални за I/O-bound workloads
        \item 100x по-евтини от threads (KB vs MB)
    \end{itemize}
    
    \item \textbf{Publisher/Subscriber}
    \begin{itemize}
        \item Decoupling чрез event broker
        \item Паралелизирано разпращане на съобщения
        \item Препратка към научна работа
    \end{itemize}
    
    \item \textbf{Комбиниране}
    \begin{itemize}
        \item Hybrid архитектури за реални системи
    \end{itemize}
\end{enumerate}
\end{frame}

\begin{frame}{Връзка с курса}
\textbf{Модул 2: Асинхронно програмиране с .NET}

\begin{itemize}
    \item \textbf{Лекция 2-2:} Подходи за асинхронен код $\rightarrow$ Thread Pools (C++)
    \item \textbf{Лекция 2-3:} Async-await шаблон $\rightarrow$ Coroutines (C++20)
    \item \textbf{Лекция 2-4:} Паралелен достъп до данни $\rightarrow$ Lock-free structures
    \item \textbf{Лекция 2-1:} Оптимизация и performance $\rightarrow$ Benchmarks (днес)
\end{itemize}

\vspace{0.4cm}

\textbf{C++ vs .NET паралели:}
\begin{itemize}
    \item .NET Task Parallel Library $\leftrightarrow$ C++ Thread Pool
    \item .NET async/await $\leftrightarrow$ C++ coroutines (co\_await)
    \item .NET Concurrent Collections $\leftrightarrow$ C++ lock-free queues
    \item .NET Events $\leftrightarrow$ C++ Publisher/Subscriber pattern
\end{itemize}

\vspace{0.4cm}

\textbf{Тази лекция разширява:}
\begin{itemize}
    \item Low-level имплементации на високо-ниво концепции
    \item Performance considerations (защо Thread Pool вместо threads?)
    \item Практически шаблони за комуникация (Pub/Sub)
\end{itemize}
\end{frame}

\begin{frame}{Препоръчителна литература}
\footnotesize
\begin{columns}
    \column{0.45\textwidth}
        \textbf{Книги:}
        \begin{itemize}
            \item "C++ Concurrency in Action" – Anthony Williams
            \item "The Art of Multiprocessor Programming" – Herlihy \& Shavit
            \item "Programming with POSIX Threads" – David Butenhof
        \end{itemize}
        \textbf{Papers \& Talks:}
        \begin{itemize}
            \item "Lock-Free Data Structures" – Michael \& Scott
            \item "RCU (Read-Copy-Update)" – McKenney
            \item "Optimizing Asynchronous Event Dispatch in Modern C++ Publish/Subscribe Systems" – Alex Tsvetanov
        \end{itemize}
    \column{0.45\textwidth}
        \textbf{Lock-Free Queue имплементации и talks:}
        \begin{itemize}
            \item \href{https://www.youtube.com/watch?v=bjz_bMNNWRk}{"User API and C++ Implementation of MPMC Lock Free Queue"} – Erez Strauss, CppCon 2024
            \item \href{https://www.youtube.com/watch?v=_qaKkHuHYE0}{"Building a Lock-free MPMC Queue for Tcmalloc"} – Matt Kulukundis, CppCon 2021
            \item \href{https://github.com/DNedic/lockfree}{github.com/DNedic/lockfree} – Djordje Nedic, Pablo Duboue, Lennart Schierling
        \end{itemize}
        
        \textbf{Online ресурси:}
        \begin{itemize}
            \item \href{https://en.cppreference.com}{cppreference.com} – coroutines, atomics, memory ordering
            \item \href{https://preshing.com}{preshing.com} – lock-free programming blog
            \item \href{https://www.1024cores.net/home/lock-free-algorithms}{1024cores.net} – Dmitry Vyukov's concurrency blog
        \end{itemize}
\end{columns}
\end{frame}

\begin{frame}{Въпроси и дискусия}
\centering
\Huge{Въпроси?}

\vspace{4cm}
\textit{Благодаря за вниманието!}

\vspace{0.5cm}
\small
Контакт: atsvetanov{\texttt{@}}tu-sofia.bg | GitHub: github.com/Alex-Tsvetanov
\end{frame}

\end{document}
